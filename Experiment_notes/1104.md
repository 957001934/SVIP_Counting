# Date 1104

### Experiment 1

multi-scales , RepNet ,Video-swin-transformer pretrain model

### hyperparameter

视频长度抽取32帧，32x224x224  
scale [1]  
epoch 50  
similarity matrix heads=4 learning rate 1e-5x(1,0.8,0.64)[10,30]  
loss=loss1+loss2

### main work

encoder的输出接入全连接的网络进行了更改,从[b,f * num]->[b,f,1],从全局混合全连接变为单帧全连接. loss = loss1+loss2

### result

loss变为收敛了，实验证明不能将MAE加入loss会导致难以收敛 tensoboard scalar1104

### Experiment 2

### hyperparameter

视频长度抽取64帧，64x224x224  
scale [1]  
epoch 50  
similarity matrix heads=4  
learning rate 1e-5x(1,0.8,0.64)[10,30]    
loss=loss1+loss2

### main work

dataloader num_workers=20  
num_frames=64  
前5个epoch不计算backbone的梯度，显著减小显存占用

### result

tensorboard scalar1104_2

****